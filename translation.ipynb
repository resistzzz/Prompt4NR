{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### This code is used to extract, and replace Titles, abstracts and topics lists in the news.txt dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93e4126a3f575ca2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f186e2a198f30e0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T19:12:10.197589Z",
     "start_time": "2024-06-28T19:12:07.786527Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# with open('./DATA/full_balanced_English/train.txt', 'rb') as f:\n",
    "#     train_data = pickle.load(f)\n",
    "with open('./DATA/full_balanced_English/news.txt', 'rb') as f:\n",
    "    news_data = pd.DataFrame(pickle.load(f)).T\n",
    "# with open('DATA/full_balanced_large/English_titles_large.txt', 'r', encoding='utf-8-sig') as f:\n",
    "#     news_titles = [line.strip() for line in f]\n",
    "#     \n",
    "# with open('DATA/full_balanced_large/English_abstract_large.txt', 'r', encoding='utf-8-sig') as f:\n",
    "#     news_abstracts = [line.strip() for line in f]\n",
    "# \n",
    "# with open('./DATA/full_balanced_large/news.txt', 'rb') as f:\n",
    "#     news_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf8 in position 553: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# with open('./DATA/full_balanced_English/New_English_titles.txt', 'r') as f:\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#     new_titles = [line.strip() for line in f]\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./DATA/full_balanced_English/new_English_abstracts.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8-sig\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 16\u001B[0m     new_abstracts \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m]\u001B[49m\n",
      "Cell \u001B[0;32mIn[59], line 16\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# with open('./DATA/full_balanced_English/New_English_titles.txt', 'r') as f:\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#     new_titles = [line.strip() for line in f]\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./DATA/full_balanced_English/new_English_abstracts.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8-sig\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 16\u001B[0m     new_abstracts \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m<frozen codecs>:322\u001B[0m, in \u001B[0;36mdecode\u001B[0;34m(self, input, final)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/envs/recsys/lib/python3.11/encodings/utf_8_sig.py:69\u001B[0m, in \u001B[0;36mIncrementalDecoder._buffer_decode\u001B[0;34m(self, input, errors, final)\u001B[0m\n\u001B[1;32m     66\u001B[0m             (output, consumed) \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m     67\u001B[0m                codecs\u001B[38;5;241m.\u001B[39mutf_8_decode(\u001B[38;5;28minput\u001B[39m[\u001B[38;5;241m3\u001B[39m:], errors, final)\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m (output, consumed\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m codecs\u001B[38;5;241m.\u001B[39mutf_8_decode(\u001B[38;5;28minput\u001B[39m, errors, final)\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xf8 in position 553: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "with open('./DATA/full_balanced/small_new_news.txt', 'rb') as f:\n",
    "    news_data = pickle.load(f)\n",
    "news_df = pd.DataFrame(news_data).T\n",
    "with open('./DATA/full_balanced_English/news.txt', 'rb') as f:\n",
    "    news_data1 = pickle.load(f)\n",
    "news_df1 = pd.DataFrame(news_data1).T\n",
    "\n",
    "# news_df = pd.DataFrame(news_data).T\n",
    "with open('./DATA/full_balanced_English/new_English_topics.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    new_topics = [line.strip() for line in f]\n",
    "# with open('./DATA/full_balanced_English/New_English_titles.txt', 'r') as f:\n",
    "#     new_titles = [line.strip() for line in f]\n",
    "with open('./DATA/full_balanced_English/new_English_abstracts.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    new_abstracts = [line.strip() for line in f]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:17:46.706164Z",
     "start_time": "2024-06-26T16:17:45.064098Z"
    }
   },
   "id": "cf3390c60c7e3a8c",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./DATA/full_balanced_English/new_English_abstracts.txt', 'r', encoding='unicode_escape') as f:\n",
    "    new_abstracts = [line.strip() for line in f]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:18:35.300909Z",
     "start_time": "2024-06-26T16:18:35.277676Z"
    }
   },
   "id": "c35e7d3690408b41",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "news_df['title'] = news_df1['title']\n",
    "news_df['abstract'] = new_abstracts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:19:06.481079Z",
     "start_time": "2024-06-26T16:19:06.471377Z"
    }
   },
   "id": "250c2bf525e078a3",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def export_column_to_txt(df, column_name, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for row in df[column_name]:\n",
    "            f.write(f\"{row}\\n\")\n",
    "\n",
    "# Example usage\n",
    "export_column_to_txt(news_df, 'topics', 'new_Danish_topics.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T15:30:01.567830Z",
     "start_time": "2024-06-26T15:30:00.765541Z"
    }
   },
   "id": "325d889fdc10961b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16492579-c988-4fa5-a141-59a4da62498f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T15:50:12.996226Z",
     "start_time": "2024-06-26T15:50:12.951960Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_string_to_list(s):\n",
    "    # Remove the enclosing square brackets and split by single quotes\n",
    "    items = s.strip(\"[]\").split(\"' '\")\n",
    "    # Strip any remaining single quotes and spaces\n",
    "    items = [item.strip(\"' \") for item in items]\n",
    "    return items\n",
    "\n",
    "# Applying the function to each string in the list\n",
    "new_topics = [convert_string_to_list(item) for item in new_topics]\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "news_df['topics']=nested_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:19:26.108995Z",
     "start_time": "2024-06-26T16:19:26.098366Z"
    }
   },
   "id": "acc4a7e468bf951d",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m~/miniconda3/envs/recsys/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[1;32mIn[33], line 19\u001B[0m\n    nested_list = convert_to_nested_list(new_topics)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[1;32mIn[33], line 14\u001B[0m in \u001B[1;35mconvert_to_nested_list\u001B[0m\n    converted_item = ast.literal_eval(f\"[{formatted_item}]\")\u001B[0m\n",
      "\u001B[0m  File \u001B[1;32m~/miniconda3/envs/recsys/lib/python3.11/ast.py:64\u001B[0m in \u001B[1;35mliteral_eval\u001B[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001B[0m\n",
      "\u001B[0;36m  File \u001B[0;32m~/miniconda3/envs/recsys/lib/python3.11/ast.py:50\u001B[0;36m in \u001B[0;35mparse\u001B[0;36m\n\u001B[0;31m    return compile(source, filename, mode, flags,\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m<unknown>:1\u001B[0;36m\u001B[0m\n\u001B[0;31m    [[Crime', 'Mean', 'of', 'transport', 'Car', 'Major', 'means', 'of', 'transport]]\u001B[0m\n\u001B[0m           ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Function to convert string to nested list\n",
    "def convert_to_nested_list(input_list):\n",
    "    nested_list = []\n",
    "    for item in input_list:\n",
    "        # Check if the item is an empty list\n",
    "        if item == \"[]\":\n",
    "            nested_list.append([])\n",
    "        else:\n",
    "            # Replace single quotes and concatenate with commas for splitting\n",
    "            formatted_item = item.replace(\"'\", \"\").replace(\" \", \"', '\")\n",
    "            # Convert string to list\n",
    "            converted_item = ast.literal_eval(f\"[{formatted_item}]\")\n",
    "            nested_list.append(converted_item)\n",
    "    return nested_list\n",
    "\n",
    "# Convert the input list to the desired nested list format\n",
    "nested_list = convert_to_nested_list(new_topics)\n",
    "print(nested_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:07:18.427994Z",
     "start_time": "2024-06-26T16:07:18.419764Z"
    }
   },
   "id": "47dbbbfb6f590423",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70627020f2fad21",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def column_to_txt(df, column_name, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for value in df[column_name]:\n",
    "            clean_value = str(value).replace('\\n', ' ')  # Replace newlines with spaces\n",
    "            f.write(f\"{clean_value}\\n\")\n",
    "            \n",
    "\n",
    "\n",
    "# Example usage\n",
    "column_to_txt(news_df, 'topics', 'new_Danish_topics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05e06986e62724",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_titles(news_data, news_titles):\n",
    "    if len(news_data) != len(news_titles):\n",
    "        raise ValueError(\"The length of news_titles must match the number of entries in news_data.\")\n",
    "    \n",
    "    # Create an iterator for the new titles\n",
    "    title_iterator = iter(news_titles)\n",
    "    \n",
    "    for key, value in news_data.items():\n",
    "        if isinstance(value, dict) and 'title' in value:\n",
    "            # Assign the next title from the news_titles list\n",
    "            value['title'] = next(title_iterator)\n",
    "\n",
    "english_data=replace_titles(news_data,news_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a7c48d99a9feade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:16:56.512756Z",
     "start_time": "2024-06-19T08:16:56.485880Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_titles(news_data, news_titles, news_abstract):\n",
    "    if len(news_data) != len(news_titles):\n",
    "        raise ValueError(\"The length of news_titles must match the number of entries in news_data.\")\n",
    "    \n",
    "    # Create an iterator for the new titles\n",
    "    title_iterator = iter(news_titles)\n",
    "    abstract_iterator = iter(news_abstract)\n",
    "    \n",
    "    for key, value in news_data.items():\n",
    "        if isinstance(value, dict) and 'title' in value and 'abstract' in value:\n",
    "            # Assign the next title from the news_titles list\n",
    "            value['title'] = next(title_iterator)\n",
    "            value['abstract'] = next(abstract_iterator)\n",
    "    return news_data\n",
    "\n",
    "english_data_dict=replace_titles(news_data,news_titles,news_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cc6720-1782-4e17-bb32-634716045171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T20:02:55.934342Z",
     "start_time": "2024-06-26T20:02:55.756374Z"
    }
   },
   "outputs": [],
   "source": [
    "english_data = news_data.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f1e2afc10759fc4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T16:21:38.972478Z",
     "start_time": "2024-06-26T16:21:38.839489Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./DATA/full_balanced_English/news.txt', 'wb') as f:\n",
    "    pickle.dump(news_df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
